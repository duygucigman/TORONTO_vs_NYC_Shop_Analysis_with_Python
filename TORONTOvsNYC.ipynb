{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project - The Battle of Neighborhoods (Week 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that project we are comparing neighborhoods of New York City and the city of Toronto by using Foursquare location data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Introduction to the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a senerio for open a shop/restaurant in a city. \n",
    "Firstly ,we are focusing to analyze common and different venues in downtown Toronto and the western central London to understand their culture and lifestyle. Then we can come up with an idea for the right area for opening a new place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the datasets below while starting to collect the data.\n",
    "\n",
    "<n>The postal codes of western central London : https://en.wikipedia.org/wiki/WC_postcode_area     \n",
    "<n>The postal codes of downtown Toronto : https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M     \n",
    "<n>The geographical coordinates : Python Geocoder package     \n",
    "<n>The types and locations of venues : Foursquare API     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### London Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrive London data from Wikipedia\n",
    "sourcelondon = requests.get('https://en.wikipedia.org/wiki/WC_postcode_area').text\n",
    "souplondon = BeautifulSoup(sourcelondon,'lxml')\n",
    "\n",
    "tablelondon = soup1.find('table',{'class':'wikitable sortable'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the rows to get the data\n",
    "PostalCode =[]\n",
    "PostTown = []\n",
    "Neighbourhood = []\n",
    "\n",
    "for row in table1.findAll(\"tr\"):\n",
    "    cells = row.findAll(\"th\")\n",
    "    if len(cells) == 1:\n",
    "        PostalCode.append(cells[0].find(text=True))\n",
    "    \n",
    "    cells = row.findAll(\"td\")\n",
    "    if len(cells) == 3: \n",
    "        PostTown.append(cells[0].find(text=True))\n",
    "        Neighbourhood.append(cells[1].find(text=True))\n",
    "\n",
    "london = pd.DataFrame(PostalCode, columns = ['PostalCode'])\n",
    "london['PostTown'] = PostTown\n",
    "london['Neighbourhood'] = Neighbourhood\n",
    "london.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding latitudes and longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "Latitude = []\n",
    "Longitude = []\n",
    "\n",
    "for i in london['Neighbourhood']:\n",
    "    geolocator = Nominatim(user_agent=\"ld_explorer\")\n",
    "    location = geolocator.geocode(i)\n",
    "    \n",
    "    latitude = location.latitude\n",
    "    Latitude.append(latitude)\n",
    "    \n",
    "    longitude = location.longitude\n",
    "    Longitude.append(longitude)\n",
    "    \n",
    "london['Latitude'] = Latitude\n",
    "london['Longitude'] = Longitude\n",
    "london.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping far spots away from the neighbourhoods data\n",
    "london = london.drop(london.index[3])\n",
    "london = london.drop(london.index[11])\n",
    "london.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toronto Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrive Toronto data from Wikipedia\n",
    "sourcetoronto = requests.get('https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M').text\n",
    "souptoronto = BeautifulSoup(sourcetoronto,'lxml')\n",
    "\n",
    "tabletoronto = soup2.find('table',{'class':'wikitable sortable'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the rows to get the data\n",
    "PostalCode =[]\n",
    "Borough = []\n",
    "Neighbourhood =[]\n",
    "\n",
    "for row in tabletoronto.findAll(\"tr\"):\n",
    "    cells = row.findAll(\"td\")\n",
    "    if len(cells) == 3:\n",
    "        PostalCode.append(cells[0].find(text=True))\n",
    "        Borough.append(cells[1].find(text=True))\n",
    "        Neighbourhood.append(cells[2].find(text=True))\n",
    "        \n",
    "toronto = pd.DataFrame(PostalCode, columns = ['PostalCode'])\n",
    "toronto['Borough'] = Borough\n",
    "toronto['Neighbourhood'] = Neighbourhood\n",
    "toronto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data of Toronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing 'Not assigned' data in borough column\n",
    "condition = toronto.Borough == 'Not assigned'\n",
    "toronto = toronto.drop(toronto[condition].index, axis = 0, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing 'Not assigned' data in neighborhood column and replace it with borough data\n",
    "toronto['Neighbourhood'] = toronto['Neighbourhood'].str.strip()\n",
    "\n",
    "import numpy as np\n",
    "toronto['Neighbourhood'] = np.where(toronto['Neighbourhood'] =='Not assigned', toronto['Borough'], toronto['Neighbourhood'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining Neighbourhood column by using ',' when they have the same postal code\n",
    "toronto2 = pd.DataFrame(toronto.groupby(['PostalCode','Borough'], as_index = False).agg(', '.join))\n",
    "toronto2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata = pd.read_csv('https://cocl.us/Geospatial_data')\n",
    "\n",
    "toronto3 = pd.concat([toronto2, geodata], axis=1).drop('Postal Code',axis = 1)\n",
    "toronto3.head()\n",
    "\n",
    "#We are using only downtown in Toronto\n",
    "dt_trt = toronto3[toronto3['Borough'] == 'Downtown Toronto'].reset_index(drop=True)\n",
    "dt_trt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look shortly to our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_trt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both city:\n",
    "We will visualize data in map by using folium map library.\n",
    "Then we will look at 100 venues in each neighbourhood for around 500 mt by using Foursquare API.\n",
    "Then we will machine learning algorithm called K Means Clustering for deviding neighbourhoods to 3 clusters.\n",
    "In summary section, we will compare this two results for come up with ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'London'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"ld_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of London are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# Create map of London using latitude and longitude values\n",
    "map_london = folium.Map(location=[latitude, longitude], zoom_start=12)\n",
    "\n",
    "# Add markers to map\n",
    "for lat, lng, borough, neighborhood in zip(london['Latitude'], london['Longitude'], london['PostTown'], london['Neighbourhood']):\n",
    "    label = '{}, {}'.format(neighborhood, borough)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_london)  \n",
    "    \n",
    "map_london"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foursquare API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = 'KULIKOK1JSONEBUQ1W0PCIR3DLSACJZSVOGJA3ZSIA1EEP24'\n",
    "CLIENT_SECRET = '4P32UWQ5GUBPQFZ3YJZRUMKNBWWLKKGRLLPWFDW5QOH41KSZ'\n",
    "VERSION = '20190120'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT = 100 # limit of number of venues returned by Foursquare API\n",
    "\n",
    "radius = 500 # define radius\n",
    "\n",
    "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighbourhood', \n",
    "                  'Neighbourhood Latitude', \n",
    "                  'Neighbourhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_venues = getNearbyVenues(names = london['Neighbourhood'],\n",
    "                                latitudes = london['Latitude'],\n",
    "                                longitudes = london['Longitude'])\n",
    "london_venues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many venues were returned for each neighborhood\n",
    "london_venues.groupby('Neighbourhood').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} uniques categories of all the returned venues.'.format(len(london_venues['Venue Category'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 most common venues for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_onehot = pd.get_dummies(london_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add neighborhood column back to dataframe\n",
    "london_onehot['Neighbourhood'] = london_venues['Neighbourhood'] \n",
    "\n",
    "# move neighborhood column to the first column\n",
    "fixed_columns = [london_onehot.columns[-1]] + list(london_onehot.columns[:-1])\n",
    "london_onehot = london_onehot[fixed_columns]\n",
    "\n",
    "# average frequency for each neighborhood group\n",
    "london_grouped = london_onehot.groupby('Neighbourhood').mean().reset_index()\n",
    "london_grouped.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the venues in descending order\n",
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Neighbourhood']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "london_neighborhoods_venues_sorted = pd.DataFrame(columns=columns)\n",
    "london_neighborhoods_venues_sorted['Neighbourhood'] = london_grouped['Neighbourhood']\n",
    "\n",
    "for ind in np.arange(london_grouped.shape[0]):\n",
    "    london_neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(london_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "london_neighborhoods_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "london_grouped_clustering = london_grouped.drop('Neighbourhood', 1)\n",
    "\n",
    "kclusters = 3\n",
    "kmeans = KMeans(n_clusters = kclusters, random_state = 0).fit(london_grouped_clustering)\n",
    "\n",
    "kmeans.labels_[0:10] # cluster labels generated for each row in the dataframe\n",
    "\n",
    "\n",
    "# add clustering labels\n",
    "london_neighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n",
    "\n",
    "london_merged = london\n",
    "london_merged = london_merged.join(london_neighborhoods_venues_sorted.set_index('Neighbourhood'), \n",
    "                                   on ='Neighbourhood')\n",
    "\n",
    "london_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# create map\n",
    "london_clusters = folium.Map(location=[latitude, longitude], zoom_start=12)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(london_merged['Latitude'],london_merged['Longitude'],london_merged['Neighbourhood'],london_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        fill=True,\n",
    "        fill_opacity=0.7).add_to(london_clusters)\n",
    "       \n",
    "london_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#theater\n",
    "london_merged.loc[london_merged['Cluster Labels'] == 0, \n",
    "                  london_merged.columns[[1] + list(range(5, london_merged.shape[1]))]]\n",
    "#cafe\n",
    "london_merged.loc[london_merged['Cluster Labels'] == 1, \n",
    "                  london_merged.columns[[1] + list(range(5, london_merged.shape[1]))]]\n",
    "#pub\n",
    "london_merged.loc[london_merged['Cluster Labels'] == 2, \n",
    "                  london_merged.columns[[1] + list(range(5, london_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'Downtown Toronto'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"ny_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of Downtown Toronto are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create map of Downtown Toronto using latitude and longitude values\n",
    "map_dt_trt = folium.Map(location=[latitude, longitude], zoom_start=12)\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, label in zip(dt_trt['Latitude'], dt_trt['Longitude'], dt_trt['Neighbourhood']):\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_dt_trt)  \n",
    "    \n",
    "map_dt_trt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foursquare API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_venues = getNearbyVenues(names = dt_trt['Neighbourhood'],\n",
    "                            latitudes = dt_trt['Latitude'],\n",
    "                            longitudes = dt_trt['Longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many venues were returned for each neighborhood\n",
    "dt_venues.groupby('Neighbourhood').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} uniques categories of all the returned venues.'.format(len(dt_venues['Venue Category'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 most common venues for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_onehot = pd.get_dummies(dt_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add neighborhood column back to dataframe\n",
    "dt_onehot['Neighbourhood'] = dt_venues['Neighbourhood'] \n",
    "\n",
    "# move neighborhood column to the first column\n",
    "fixed_columns = [dt_onehot.columns[-1]] + list(dt_onehot.columns[:-1])\n",
    "dt_onehot = dt_onehot[fixed_columns]\n",
    "\n",
    "# average frequency for each neighborhood group\n",
    "dt_grouped = dt_onehot.groupby('Neighbourhood').mean().reset_index()\n",
    "dt_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 5\n",
    "\n",
    "for hood in dt_grouped['Neighbourhood']:\n",
    "    print(\"----\"+hood+\"----\")\n",
    "    temp = dt_grouped[dt_grouped['Neighbourhood'] == hood].T.reset_index()\n",
    "    temp.columns = ['venue','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 2})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the venues in descending order\n",
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Neighbourhood']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "trt_neighborhoods_venues_sorted = pd.DataFrame(columns=columns)\n",
    "trt_neighborhoods_venues_sorted['Neighbourhood'] = dt_grouped['Neighbourhood']\n",
    "\n",
    "for ind in np.arange(dt_grouped.shape[0]):\n",
    "    trt_neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(dt_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "trt_neighborhoods_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_grouped_clustering = dt_grouped.drop('Neighbourhood', 1)\n",
    "\n",
    "kclusters = 6\n",
    "kmeans = KMeans(n_clusters = kclusters, random_state = 0).fit(dt_grouped_clustering)\n",
    "\n",
    "kmeans.labels_[0:10] # cluster labels generated for each row in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add clustering labels\n",
    "trt_neighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n",
    "\n",
    "dt_merged = dt_trt\n",
    "\n",
    "# merge dt_grouped with dt_trt to add latitude/longitude for each neighborhood\n",
    "dt_merged = dt_merged.join(trt_neighborhoods_venues_sorted.set_index('Neighbourhood'), \n",
    "                           on ='Neighbourhood')\n",
    "\n",
    "dt_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map\n",
    "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=12)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(dt_merged['Latitude'], dt_merged['Longitude'], dt_merged['Neighbourhood'], dt_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cafe restaurant\n",
    "dt_merged.loc[dt_merged['Cluster Labels'] == 0, \n",
    "              dt_merged.columns[[1] + list(range(5, dt_merged.shape[1]))]]\n",
    "#park\n",
    "dt_merged.loc[dt_merged['Cluster Labels'] == 1, \n",
    "              dt_merged.columns[[1] + list(range(5, dt_merged.shape[1]))]\n",
    "#grocery\n",
    "dt_merged.loc[dt_merged['Cluster Labels'] == 2, \n",
    "              dt_merged.columns[[1] + list(range(5, dt_merged.shape[1]))]\n",
    "#airport\n",
    "dt_merged.loc[dt_merged['Cluster Labels'] == 3, \n",
    "              dt_merged.columns[[1] + list(range(5, dt_merged.shape[1]))]]\n",
    "#cafe\n",
    "dt_merged.loc[dt_merged['Cluster Labels'] == 4, \n",
    "              dt_merged.columns[[1] + list(range(5, dt_merged.shape[1]))]]\n",
    "#bar              \n",
    "dt_merged.loc[dt_merged['Cluster Labels'] == 5, \n",
    "              dt_merged.columns[[1] + list(range(5, dt_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary table for Toronto vs London spot grouping in the city\n",
    "Clusters = [1,2,3,4,5]\n",
    "comparison = pd.DataFrame(Clusters, columns = ['Clusters'])\n",
    "\n",
    "London = ['Theater','Cafe','Pub','-','-']\n",
    "Toronto = ['Cafe & Restaurant','Cafe','Bar','Park',' Grocery Store']\n",
    "\n",
    "comparison['London'] = London\n",
    "comparison['Toronto'] = Toronto\n",
    "\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems in the results that London and Toronto are very similar structure. We already know that both two city are multicultural and have wide variety for cafe nad restaurants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also both cities have differences. London has lots of green areas and parks. Start a fastfood truck business can be a good option.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
